# ğŸ“š DocumentaciÃ³n TÃ©cnica - Pipeline ETL

## ğŸ—ï¸ Arquitectura del Sistema

### Diagrama de Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FUENTES DE    â”‚    â”‚   PIPELINE      â”‚    â”‚   DESTINO       â”‚
â”‚     DATOS       â”‚    â”‚      ETL        â”‚    â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ CSV Files     â”‚â”€â”€â”€â–¶â”‚ â€¢ Extract       â”‚â”€â”€â”€â–¶â”‚ â€¢ SQLite DB    â”‚
â”‚ â€¢ APIs          â”‚    â”‚ â€¢ Transform     â”‚    â”‚ â€¢ Reports       â”‚
â”‚ â€¢ Databases     â”‚    â”‚ â€¢ Load          â”‚    â”‚ â€¢ Visualizationsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principales

#### 1. **Extractors** (`src/extractors/`)
- **DataExtractor**: Clase principal para extraer datos
- Soporte para mÃºltiples fuentes:
  - Archivos CSV
  - APIs REST (simuladas)
  - Bases de datos SQLite
- ValidaciÃ³n de datos extraÃ­dos
- Manejo de errores robusto

#### 2. **Transformers** (`src/transformers/`)
- **DataTransformer**: Clase principal para transformar datos
- Funcionalidades:
  - Limpieza de datos (duplicados, valores nulos)
  - ValidaciÃ³n de tipos de datos
  - Transformaciones especÃ­ficas por tabla
  - CreaciÃ³n de tablas derivadas
  - Manejo de outliers

#### 3. **Loaders** (`src/loaders/`)
- **DataLoader**: Clase principal para cargar datos
- CaracterÃ­sticas:
  - CreaciÃ³n automÃ¡tica de esquemas
  - Carga masiva de datos
  - CreaciÃ³n de Ã­ndices
  - EstadÃ­sticas de carga
  - Consultas personalizadas

#### 4. **Utils** (`src/utils/`)
- **ConfigLoader**: GestiÃ³n de configuraciÃ³n YAML
- **Logger**: Sistema de logging personalizado
- **ReportGenerator**: GeneraciÃ³n de reportes y visualizaciones

## ğŸ”§ ConfiguraciÃ³n del Sistema

### Archivo de ConfiguraciÃ³n (`config/config.yaml`)

```yaml
project:
  name: "ETL E-commerce Analytics"
  version: "1.0.0"

paths:
  data_raw: "data/raw"           # Datos sin procesar
  data_processed: "data/processed" # Datos procesados
  data_reports: "data/reports"   # Reportes generados
  logs: "logs"                   # Archivos de log

database:
  type: "sqlite"
  path: "data/processed/ecommerce_analytics.db"
  tables: ["ventas", "productos", "clientes", "categorias"]

validation:
  required_columns:
    ventas: ["id", "fecha", "producto_id", "cliente_id", "cantidad", "precio"]
    productos: ["id", "nombre", "categoria", "precio"]
    clientes: ["id", "nombre", "email", "ciudad"]

cleaning:
  remove_duplicates: true
  fill_missing:
    strategy: "forward"
    numeric: 0
    categorical: "Unknown"
  outliers:
    method: "iqr"
    threshold: 1.5
```

## ğŸ“Š Esquema de Base de Datos

### Tablas Principales

#### 1. **ventas**
```sql
CREATE TABLE ventas (
    id INTEGER PRIMARY KEY,
    fecha DATETIME NOT NULL,
    producto_id INTEGER NOT NULL,
    cliente_id INTEGER NOT NULL,
    cantidad INTEGER NOT NULL,
    precio REAL NOT NULL,
    total REAL NOT NULL,
    mes INTEGER,
    aÃ±o INTEGER,
    dia_semana TEXT
);
```

#### 2. **productos**
```sql
CREATE TABLE productos (
    id INTEGER PRIMARY KEY,
    nombre TEXT NOT NULL,
    categoria TEXT NOT NULL,
    precio REAL NOT NULL,
    stock INTEGER,
    descripcion TEXT
);
```

#### 3. **clientes**
```sql
CREATE TABLE clientes (
    id INTEGER PRIMARY KEY,
    nombre TEXT NOT NULL,
    email TEXT NOT NULL,
    ciudad TEXT NOT NULL,
    telefono TEXT,
    fecha_registro DATETIME
);
```

### Tablas Derivadas

#### 1. **ventas_por_producto**
```sql
CREATE TABLE ventas_por_producto (
    producto_id INTEGER PRIMARY KEY,
    cantidad_total INTEGER NOT NULL,
    total_ventas REAL NOT NULL,
    num_ventas INTEGER NOT NULL,
    nombre_producto TEXT,
    categoria TEXT
);
```

#### 2. **ventas_por_cliente**
```sql
CREATE TABLE ventas_por_cliente (
    cliente_id INTEGER PRIMARY KEY,
    cantidad_total INTEGER NOT NULL,
    total_compras REAL NOT NULL,
    num_compras INTEGER NOT NULL,
    nombre_cliente TEXT,
    ciudad TEXT
);
```

#### 3. **ventas_por_categoria**
```sql
CREATE TABLE ventas_por_categoria (
    categoria TEXT PRIMARY KEY,
    cantidad_total INTEGER NOT NULL,
    total_ventas REAL NOT NULL,
    num_ventas INTEGER NOT NULL
);
```

## ğŸ”„ Flujo de Datos

### 1. **ExtracciÃ³n (Extract)**
```python
# Ejemplo de extracciÃ³n
extractor = DataExtractor(config)
raw_data = extractor.extract_all()

# Resultado: Dict[str, pd.DataFrame]
{
    'ventas': DataFrame(...),
    'productos': DataFrame(...),
    'clientes': DataFrame(...),
    'categorias': DataFrame(...),
    'inventario': DataFrame(...)
}
```

### 2. **TransformaciÃ³n (Transform)**
```python
# Ejemplo de transformaciÃ³n
transformer = DataTransformer(config)
transformed_data = transformer.transform_all(raw_data)

# Transformaciones aplicadas:
# - Limpieza de datos
# - ValidaciÃ³n de tipos
# - CreaciÃ³n de columnas derivadas
# - GeneraciÃ³n de tablas agregadas
```

### 3. **Carga (Load)**
```python
# Ejemplo de carga
loader = DataLoader(config)
success = loader.load_all(transformed_data)

# Resultado: Base de datos SQLite con todas las tablas
```

## ğŸ“ˆ Reportes y Visualizaciones

### Tipos de Reportes Generados

1. **Reportes de Ventas**
   - Ventas por dÃ­a (grÃ¡fico de lÃ­neas)
   - Ventas por categorÃ­a (grÃ¡fico de barras)
   - Top productos mÃ¡s vendidos (grÃ¡fico horizontal)

2. **Reportes de Productos**
   - Estado del inventario (grÃ¡fico de barras con colores)
   - Productos con stock bajo (indicadores)

3. **Reportes de Clientes**
   - Top clientes (grÃ¡fico horizontal)
   - Ventas por ciudad (grÃ¡fico de barras)

4. **Reporte General**
   - MÃ©tricas principales (dashboard)
   - Resumen ejecutivo

### Formatos de Salida

- **GrÃ¡ficos**: PNG (alta resoluciÃ³n)
- **Datos**: CSV
- **Reporte completo**: HTML interactivo
- **MÃ©tricas**: JSON

## ğŸ§ª Testing

### Estructura de Tests

```
tests/
â”œâ”€â”€ __init__.py
â””â”€â”€ test_etl_pipeline.py
```

### Tipos de Tests

1. **Tests Unitarios**
   - ConfigLoader
   - DataExtractor
   - DataTransformer
   - DataLoader

2. **Tests de IntegraciÃ³n**
   - Pipeline completo
   - ValidaciÃ³n de datos
   - Manejo de errores

3. **Tests de Datos**
   - Limpieza de datos
   - Transformaciones especÃ­ficas

### Ejecutar Tests

```bash
# Ejecutar todos los tests
pytest tests/ -v

# Ejecutar con cobertura
pytest tests/ --cov=src --cov-report=html

# Ejecutar tests especÃ­ficos
pytest tests/test_etl_pipeline.py::TestETLPipeline::test_data_extractor -v
```

## ğŸ” Consultas SQL de Ejemplo

### AnÃ¡lisis de Ventas

```sql
-- Top 10 productos mÃ¡s vendidos
SELECT 
    vpp.nombre_producto,
    vpp.total_ventas,
    vpp.num_ventas,
    ROUND(vpp.total_ventas / vpp.num_ventas, 2) as ticket_promedio
FROM ventas_por_producto vpp
ORDER BY vpp.total_ventas DESC
LIMIT 10;

-- Ventas por mes
SELECT 
    v.aÃ±o,
    v.mes,
    COUNT(*) as num_ventas,
    SUM(v.total) as total_ventas,
    AVG(v.total) as ticket_promedio
FROM ventas v
GROUP BY v.aÃ±o, v.mes
ORDER BY v.aÃ±o, v.mes;

-- Clientes mÃ¡s valiosos
SELECT 
    vpc.nombre_cliente,
    vpc.ciudad,
    vpc.total_compras,
    vpc.num_compras,
    ROUND(vpc.total_compras / vpc.num_compras, 2) as ticket_promedio
FROM ventas_por_cliente vpc
ORDER BY vpc.total_compras DESC
LIMIT 10;
```

### AnÃ¡lisis de Inventario

```sql
-- Productos con stock bajo
SELECT 
    p.nombre,
    p.categoria,
    i.stock_actual,
    i.stock_minimo,
    CASE 
        WHEN i.stock_actual <= i.stock_minimo THEN 'CRÃTICO'
        WHEN i.stock_actual <= i.stock_minimo * 1.5 THEN 'BAJO'
        ELSE 'OK'
    END as estado_stock
FROM inventario i
JOIN productos p ON i.producto_id = p.id
WHERE i.stock_actual <= i.stock_minimo * 1.5
ORDER BY i.stock_actual ASC;

-- AnÃ¡lisis de categorÃ­as
SELECT 
    p.categoria,
    COUNT(*) as num_productos,
    AVG(p.precio) as precio_promedio,
    SUM(i.stock_actual) as stock_total,
    COUNT(CASE WHEN i.stock_bajo = 1 THEN 1 END) as productos_stock_bajo
FROM productos p
JOIN inventario i ON p.id = i.producto_id
GROUP BY p.categoria
ORDER BY num_productos DESC;
```

## ğŸš€ Optimizaciones y Mejoras

### Optimizaciones Implementadas

1. **Procesamiento por Lotes**
   - Carga de datos en chunks
   - Procesamiento paralelo donde es posible

2. **Ãndices de Base de Datos**
   - Ãndices en columnas frecuentemente consultadas
   - OptimizaciÃ³n de consultas

3. **Manejo de Memoria**
   - Procesamiento eficiente de DataFrames
   - Limpieza automÃ¡tica de memoria

### Posibles Mejoras Futuras

1. **Escalabilidad**
   - Soporte para bases de datos distribuidas
   - Procesamiento en paralelo con multiprocessing

2. **Monitoreo**
   - MÃ©tricas de rendimiento
   - Alertas automÃ¡ticas

3. **AutomatizaciÃ³n**
   - ProgramaciÃ³n de tareas (cron jobs)
   - IntegraciÃ³n con orquestadores (Airflow)

4. **Seguridad**
   - EncriptaciÃ³n de datos sensibles
   - AutenticaciÃ³n y autorizaciÃ³n

## ğŸ› Troubleshooting

### Problemas Comunes

#### 1. **Error de ImportaciÃ³n**
```bash
# SoluciÃ³n: Instalar dependencias
pip install -r requirements.txt
```

#### 2. **Error de Permisos**
```bash
# SoluciÃ³n: Verificar permisos de directorios
chmod -R 755 data/
chmod -R 755 logs/
```

#### 3. **Error de Base de Datos**
```bash
# SoluciÃ³n: Verificar que SQLite estÃ© disponible
python -c "import sqlite3; print('SQLite OK')"
```

#### 4. **Error de Memoria**
```python
# SoluciÃ³n: Reducir tamaÃ±o de chunks
config.set('processing.chunk_size', 1000)
```

### Logs y Debugging

Los logs se guardan en `logs/` con diferentes niveles:
- `info.log`: InformaciÃ³n general
- `error.log`: Errores y excepciones
- `debug.log`: InformaciÃ³n detallada

Para activar modo debug:
```python
logger = setup_logger(level="DEBUG")
```

## ğŸ“š Referencias y Recursos

### DocumentaciÃ³n de LibrerÃ­as
- [pandas](https://pandas.pydata.org/docs/)
- [SQLAlchemy](https://docs.sqlalchemy.org/)
- [matplotlib](https://matplotlib.org/stable/contents.html)
- [seaborn](https://seaborn.pydata.org/)

### Mejores PrÃ¡cticas
- [Python ETL Best Practices](https://www.databricks.com/blog/2017/10/30/from-etl-to-streaming-with-apache-kafka-and-databricks.html)
- [Data Pipeline Design Patterns](https://martinfowler.com/articles/data-pipeline-design-patterns.html)

### Herramientas Relacionadas
- [Apache Airflow](https://airflow.apache.org/)
- [Prefect](https://www.prefect.io/)
- [DBT](https://www.getdbt.com/)

---

*Esta documentaciÃ³n se actualiza regularmente. Para contribuir, consulta el README.md principal.* 