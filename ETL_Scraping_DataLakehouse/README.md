# üöÄ Competitive Price Intelligence Platform

## üìã Descripci√≥n del Proyecto

**Competitive Price Intelligence Platform** es una soluci√≥n completa de ingenier√≠a de datos que automatiza la recolecci√≥n, procesamiento y an√°lisis de precios de productos de la competencia en e-commerce. Esta plataforma permite a las empresas tomar decisiones estrat√©gicas de precios basadas en datos en tiempo real.

### üéØ Caso de Uso Real

**Problema de Negocio**: Una empresa de e-commerce necesita mantener precios competitivos pero no tiene visibilidad de los precios de la competencia en tiempo real.

**Soluci√≥n**: Sistema automatizado que:
- Extrae precios de m√∫ltiples competidores
- Procesa y almacena datos en un data lakehouse
- Genera insights para decisiones de precios
- Proporciona alertas de cambios de precios

**ROI Esperado**: 15-25% de mejora en m√°rgenes de beneficio mediante optimizaci√≥n de precios.

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   WEB SCRAPING  ‚îÇ    ‚îÇ   DATA LAKE     ‚îÇ    ‚îÇ      DBT        ‚îÇ    ‚îÇ   ANALYTICS     ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Selenium      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Parquet Files ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Transformations‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Power BI      ‚îÇ
‚îÇ ‚Ä¢ Scrapy        ‚îÇ    ‚îÇ ‚Ä¢ Delta Lake    ‚îÇ    ‚îÇ ‚Ä¢ Data Models   ‚îÇ    ‚îÇ ‚Ä¢ Tableau       ‚îÇ
‚îÇ ‚Ä¢ APIs          ‚îÇ    ‚îÇ ‚Ä¢ S3/MinIO      ‚îÇ    ‚îÇ ‚Ä¢ Testing       ‚îÇ    ‚îÇ ‚Ä¢ Alerts        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚ñº                       ‚ñº                       ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ORCHESTRATION ‚îÇ    ‚îÇ   MONITORING    ‚îÇ    ‚îÇ   DATA QUALITY  ‚îÇ    ‚îÇ   API ENDPOINTS ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Apache Airflow‚îÇ    ‚îÇ ‚Ä¢ Grafana       ‚îÇ    ‚îÇ ‚Ä¢ Great Expect. ‚îÇ    ‚îÇ ‚Ä¢ FastAPI       ‚îÇ
‚îÇ ‚Ä¢ Prefect       ‚îÇ    ‚îÇ ‚Ä¢ Prometheus    ‚îÇ    ‚îÇ ‚Ä¢ Data Tests    ‚îÇ    ‚îÇ ‚Ä¢ REST API      ‚îÇ
‚îÇ ‚Ä¢ Cron Jobs     ‚îÇ    ‚îÇ ‚Ä¢ Logs          ‚îÇ    ‚îÇ ‚Ä¢ Validation    ‚îÇ    ‚îÇ ‚Ä¢ Webhooks      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üõ†Ô∏è Stack Tecnol√≥gico

### Core Technologies
- **Python 3.9+**: Lenguaje principal
- **Apache Airflow**: Orquestaci√≥n de workflows
- **DBT (Data Build Tool)**: Transformaciones de datos
- **Delta Lake**: Data lakehouse
- **DuckDB**: Base de datos anal√≠tica
- **Selenium/Scrapy**: Web scraping

### Infrastructure
- **Docker**: Containerizaci√≥n
- **MinIO**: Object storage (S3 compatible)
- **Grafana**: Monitoreo y visualizaci√≥n
- **FastAPI**: API REST

### Data Quality & Testing
- **Great Expectations**: Validaci√≥n de datos
- **pytest**: Testing unitario
- **DBT Tests**: Testing de datos

## üì¶ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos
```bash
# Python 3.9+
python --version

# Docker
docker --version

# Git
git --version
```

### 1. Clonar el Repositorio
```bash
git clone https://github.com/tu-usuario/competitive-price-intelligence.git
cd competitive-price-intelligence
```

### 2. Configurar Entorno Virtual
```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno (Windows)
venv\Scripts\activate

# Activar entorno (Linux/Mac)
source venv/bin/activate
```

### 3. Instalar Dependencias
```bash
# Instalar dependencias de Python
pip install -r requirements.txt

# Instalar DBT
pip install dbt-core dbt-duckdb

# Instalar Great Expectations
pip install great-expectations
```

### 4. Configurar Variables de Entorno
```bash
# Copiar archivo de ejemplo
cp .env.example .env

# Editar variables de entorno
nano .env
```

### 5. Inicializar DBT
```bash
# Navegar al directorio DBT
cd dbt_project

# Inicializar proyecto DBT
dbt init competitive_pricing

# Instalar dependencias
dbt deps
```

### 6. Levantar Infraestructura con Docker
```bash
# Construir y levantar servicios
docker-compose up -d

# Verificar servicios
docker-compose ps
```

## üöÄ Uso del Sistema

### Ejecuci√≥n Manual

#### 1. Scraping de Datos
```bash
# Ejecutar scraping de Amazon
python src/scrapers/amazon_scraper.py

# Ejecutar scraping de MercadoLibre
python src/scrapers/mercadolibre_scraper.py

# Ejecutar todos los scrapers
python main.py --stage scrape
```

#### 2. Procesamiento de Datos
```bash
# Transformar datos con DBT
cd dbt_project
dbt run

# Ejecutar tests
dbt test

# Generar documentaci√≥n
dbt docs generate
dbt docs serve
```

#### 3. An√°lisis y Reportes
```bash
# Generar reportes de precios
python src/utils/report_generator.py

# Ejecutar an√°lisis de competitividad
python src/analytics/price_analysis.py
```

### Ejecuci√≥n Automatizada

#### Con Apache Airflow
```bash
# Acceder a la interfaz de Airflow
# http://localhost:8080

# Activar DAGs
# - price_scraping_dag
# - data_processing_dag
# - reporting_dag
```

#### Con Prefect
```bash
# Iniciar servidor de Prefect
prefect server start

# Ejecutar deployment
prefect deployment run price-intelligence/main-flow
```

## üìä Estructura del Proyecto

```
competitive-price-intelligence/
‚îú‚îÄ‚îÄ üìÑ README.md                    # Documentaci√≥n principal
‚îú‚îÄ‚îÄ üìÑ requirements.txt             # Dependencias Python
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml           # Orquestaci√≥n de servicios
‚îú‚îÄ‚îÄ üìÑ .env.example                 # Variables de entorno
‚îú‚îÄ‚îÄ üìÑ main.py                      # Script principal
‚îú‚îÄ‚îÄ üìÑ LICENSE                      # Licencia MIT
‚îú‚îÄ‚îÄ üìÑ .gitignore                   # Archivos a ignorar
‚îú‚îÄ‚îÄ üìÑ DOCUMENTACION.md             # Documentaci√≥n t√©cnica
‚îú‚îÄ‚îÄ üìÅ src/                         # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ scrapers/                # Web scrapers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ amazon_scraper.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ mercadolibre_scraper.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ base_scraper.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ transformers/            # Transformaciones
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ loaders/                 # Carga de datos
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ utils/                   # Utilidades
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ analytics/               # An√°lisis
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ orchestration/           # Orquestaci√≥n
‚îú‚îÄ‚îÄ üìÅ dbt_project/                 # Proyecto DBT
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ models/                  # Modelos de datos
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ tests/                   # Tests de datos
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ macros/                  # Macros DBT
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ dbt_project.yml          # Configuraci√≥n DBT
‚îú‚îÄ‚îÄ üìÅ data/                        # Datos
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ raw/                     # Datos sin procesar
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ processed/               # Datos procesados
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ reports/                 # Reportes
‚îú‚îÄ‚îÄ üìÅ config/                      # Configuraciones
‚îú‚îÄ‚îÄ üìÅ docker/                      # Configuraci√≥n Docker
‚îú‚îÄ‚îÄ üìÅ tests/                       # Tests unitarios
‚îî‚îÄ‚îÄ üìÅ logs/                        # Logs del sistema
```

## üîç Funcionalidades Principales

### 1. Web Scraping Inteligente
- **Multi-plataforma**: Amazon, MercadoLibre, eBay, etc.
- **Anti-detecci√≥n**: Rotaci√≥n de User-Agents, proxies
- **Rate Limiting**: Respeto a robots.txt
- **Retry Logic**: Manejo de errores robusto

### 2. Data Lakehouse
- **Formato Delta**: ACID transactions
- **Particionado**: Por fecha y categor√≠a
- **Compresi√≥n**: Optimizaci√≥n de almacenamiento
- **Versionado**: Historial de cambios

### 3. Transformaciones con DBT
- **Modelos Incrementales**: Procesamiento eficiente
- **Tests de Calidad**: Validaci√≥n autom√°tica
- **Documentaci√≥n**: Auto-generada
- **Lineage**: Trazabilidad de datos

### 4. An√°lisis de Precios
- **Price Positioning**: Posicionamiento vs competencia
- **Price Elasticity**: Elasticidad de precios
- **Market Share**: Cuota de mercado
- **Alertas**: Cambios significativos

### 5. Monitoreo y Alertas
- **Dashboards**: Grafana + Prometheus
- **Alertas**: Email, Slack, Webhook
- **Logs**: Centralizados y estructurados
- **M√©tricas**: KPIs de negocio

## üìà Modelos de Datos

### Raw Layer (Bronze)
```sql
-- Productos extra√≠dos
CREATE TABLE raw_products (
    id STRING,
    name STRING,
    price DECIMAL(10,2),
    competitor STRING,
    category STRING,
    url STRING,
    scraped_at TIMESTAMP,
    raw_data JSON
);

-- Historial de precios
CREATE TABLE raw_price_history (
    product_id STRING,
    price DECIMAL(10,2),
    competitor STRING,
    scraped_at TIMESTAMP,
    availability BOOLEAN
);
```

### Processed Layer (Silver)
```sql
-- Productos normalizados
CREATE TABLE dim_products (
    product_id STRING,
    name STRING,
    category STRING,
    brand STRING,
    competitor STRING,
    url STRING,
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

-- Fact table de precios
CREATE TABLE fact_prices (
    product_id STRING,
    competitor STRING,
    price DECIMAL(10,2),
    date_id INTEGER,
    availability BOOLEAN,
    price_change DECIMAL(10,2),
    price_change_pct DECIMAL(5,2)
);
```

### Analytics Layer (Gold)
```sql
-- KPIs de precios
CREATE TABLE kpi_price_competitiveness (
    date_id INTEGER,
    category STRING,
    avg_price DECIMAL(10,2),
    min_price DECIMAL(10,2),
    max_price DECIMAL(10,2),
    price_variance DECIMAL(10,2),
    products_count INTEGER
);

-- Alertas de precios
CREATE TABLE price_alerts (
    alert_id STRING,
    product_id STRING,
    alert_type STRING,
    old_price DECIMAL(10,2),
    new_price DECIMAL(10,2),
    change_pct DECIMAL(5,2),
    created_at TIMESTAMP
);
```

## üß™ Testing y Calidad de Datos

### Tests Unitarios
```bash
# Ejecutar tests
pytest tests/ -v

# Con cobertura
pytest tests/ --cov=src --cov-report=html
```

### Tests de Datos (DBT)
```bash
# Ejecutar tests DBT
dbt test

# Tests espec√≠ficos
dbt test --models dim_products
```

### Great Expectations
```bash
# Validar datos
python src/utils/data_validation.py

# Generar suite de validaci√≥n
great_expectations suite new
```

## üìä Dashboards y Reportes

### KPIs Principales
- **Price Competitiveness Index**: √çndice de competitividad
- **Market Share by Price Range**: Cuota por rango de precios
- **Price Change Velocity**: Velocidad de cambios
- **Competitor Price Distribution**: Distribuci√≥n de precios

### Alertas Autom√°ticas
- **Price Drops > 10%**: Ca√≠das significativas
- **New Competitor Entry**: Nuevos competidores
- **Stock Outages**: Agotamiento de stock
- **Price Wars**: Guerras de precios

## üîß Configuraci√≥n Avanzada

### Variables de Entorno
```bash
# Scraping
SCRAPER_DELAY=2
SCRAPER_TIMEOUT=30
SCRAPER_RETRIES=3

# Database
DATABASE_URL=duckdb:///data/warehouse.db
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# Airflow
AIRFLOW_HOME=./airflow
AIRFLOW__CORE__EXECUTOR=LocalExecutor

# Monitoring
GRAFANA_URL=http://localhost:3000
PROMETHEUS_URL=http://localhost:9090
```

### Configuraci√≥n DBT
```yaml
# dbt_project.yml
name: 'competitive_pricing'
version: '1.0.0'
config-version: 2

profile: 'competitive_pricing'

models:
  competitive_pricing:
    staging:
      +materialized: view
    marts:
      +materialized: table
    intermediate:
      +materialized: incremental
```

## üöÄ Deployment

### Desarrollo Local
```bash
# Levantar servicios
docker-compose up -d

# Ejecutar pipeline completo
python main.py --full-pipeline

# Monitorear logs
docker-compose logs -f
```

### Producci√≥n
```bash
# Usar docker-compose.prod.yml
docker-compose -f docker-compose.prod.yml up -d

# Configurar backups
./scripts/backup.sh

# Monitorear m√©tricas
./scripts/monitoring.sh
```

## üìà M√©tricas de Negocio

### ROI Esperado
- **15-25%** mejora en m√°rgenes de beneficio
- **30-40%** reducci√≥n en tiempo de an√°lisis
- **50-60%** mejora en precisi√≥n de precios

### KPIs T√©cnicos
- **99.9%** uptime del sistema
- **< 5 minutos** latencia de datos
- **< 1%** tasa de error en scraping
- **100%** cobertura de tests

## ü§ù Contribuci√≥n

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver [LICENSE](LICENSE) para detalles.

## üë®‚Äçüíª Autor

**Tu Nombre** - Senior Data Engineer
- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)
- Portfolio: [tu-portfolio.com](https://tu-portfolio.com)

## üôè Agradecimientos

- Comunidad de DBT por las mejores pr√°cticas
- Apache Airflow por la orquestaci√≥n robusta
- Delta Lake por el data lakehouse
- Herramientas open source utilizadas

---

‚≠ê **¬°No olvides dar una estrella al repositorio si te fue √∫til!**

## üìû Soporte

Para soporte t√©cnico o consultas comerciales:
- üìß Email: tu-email@ejemplo.com
- üí¨ Slack: [Canal de soporte](https://slack.com/app_redirect?channel=soporte)
- üìñ Docs: [Documentaci√≥n completa](DOCUMENTACION.md) 